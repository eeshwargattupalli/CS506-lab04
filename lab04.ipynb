{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "03854de4",
      "metadata": {},
      "source": [
        "### Packages!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d78316",
      "metadata": {},
      "outputs": [],
      "source": [
        "#pip install numpy pandas matplotlib scikit-learn\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, silhouette_samples\n",
        "import matplotlib.cm as cm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "141952d7",
      "metadata": {},
      "source": [
        "### Creating data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a7dfe5f",
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "# Number of hashtags per category\n",
        "n_per_cluster = 60\n",
        "\n",
        "# Social media hashtag dataset\n",
        "# Features (intentionally on very different scales):\n",
        "#   - engagement_rate: % likes + comments + shares per post (0-100)\n",
        "#   - daily_usage: posts per day using the hashtag (roughly 10 -> 60,000+)\n",
        "#   - avg_reach: average impressions per post (roughly 1,000 -> 100,000)\n",
        "\n",
        "\n",
        "# Cluster 1: Viral/Trending hashtags (#fyp, #viral, #trending)\n",
        "# High engagement, very high daily usage, high reach\n",
        "viral_engagement = np.random.normal(75, 8, n_per_cluster)\n",
        "viral_usage = np.random.normal(85, 10, n_per_cluster)\n",
        "viral_reach = np.random.normal(80, 12, n_per_cluster)\n",
        "\n",
        "# Cluster 2: Niche Community hashtags (#sourdoughbakers, #vintagevinyl, #aquascaping)\n",
        "# Moderate-high engagement (loyal community), low daily usage, moderate reach\n",
        "niche_engagement = np.random.normal(65, 10, n_per_cluster)\n",
        "niche_usage = np.random.normal(20, 8, n_per_cluster)\n",
        "niche_reach = np.random.normal(30, 10, n_per_cluster)\n",
        "\n",
        "# Cluster 3: Brand hashtags (#nike, #starbucks, #apple)\n",
        "# Lower engagement (perceived as ads), high daily usage, moderate reach\n",
        "brand_engagement = np.random.normal(25, 8, n_per_cluster)\n",
        "brand_usage = np.random.normal(70, 12, n_per_cluster)\n",
        "brand_reach = np.random.normal(55, 15, n_per_cluster)\n",
        "\n",
        "# Cluster 4: Generic hashtags (#love, #instagood, #photooftheday)\n",
        "# Moderate engagement, very high usage, moderate reach (saturated)\n",
        "evergreen_engagement = np.random.normal(40, 12, n_per_cluster)\n",
        "evergreen_usage = np.random.normal(95, 5, n_per_cluster)\n",
        "evergreen_reach = np.random.normal(45, 10, n_per_cluster)\n",
        "\n",
        "# Cluster 5: Event hashtags (#bostonmarathon, #sxsw, #coachella)\n",
        "# High engagement (passionate attendees), moderate usage, high reach (media coverage)\n",
        "event_engagement = np.random.normal(70, 10, n_per_cluster)\n",
        "event_usage = np.random.normal(50, 15, n_per_cluster)\n",
        "event_reach = np.random.normal(70, 12, n_per_cluster)\n",
        "\n",
        "# Combine all clusters. We are going to group each of the metrics for each type of hashtag.\n",
        "engagement = np.concatenate([viral_engagement, niche_engagement, brand_engagement, \n",
        "                             evergreen_engagement, event_engagement])\n",
        "usage = np.concatenate([viral_usage, niche_usage, brand_usage, \n",
        "                        evergreen_usage, event_usage])\n",
        "reach = np.concatenate([viral_reach, niche_reach, brand_reach, \n",
        "                        evergreen_reach, event_reach])\n",
        "\n",
        "# Clip values to valid ranges (0-100)\n",
        "engagement = np.clip(engagement, 0, 100)\n",
        "usage = np.clip(usage, 0, 100)\n",
        "reach = np.clip(reach, 0, 100)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82ec4fb1",
      "metadata": {},
      "source": [
        "### TODO: create data frame for visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1c78c3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create DataFrame with the format col_1 = engagement_rate, col_2 = daily_usage, col_3 = avg_reach\n",
        "# Note: we intentionally put features on very different scales.\n",
        "df = ...\n",
        "\n",
        "# True labels (for reference, not used in clustering)\n",
        "true_labels = np.repeat([0, 1, 2, 3, 4], n_per_cluster)\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nDataset preview:\")\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fab97fdd",
      "metadata": {},
      "source": [
        "### Visualizing the Hashtag Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2190955b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2D scatter plots to visualize the data\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# engagement vs usage\n",
        "axes[0].scatter(df['engagement_rate'], df['daily_usage'], alpha=0.6, s=30)\n",
        "axes[0].set_xlabel('Engagement Rate')\n",
        "axes[0].set_ylabel('Daily Usage')\n",
        "axes[0].set_title('Engagement vs Daily Usage')\n",
        "\n",
        "# engagement vs reach\n",
        "axes[1].scatter(df['engagement_rate'], df['avg_reach'], alpha=0.6, s=30)\n",
        "axes[1].set_xlabel('Engagement Rate')\n",
        "axes[1].set_ylabel('Average Reach')\n",
        "axes[1].set_title('Engagement vs Reach')\n",
        "\n",
        "#TODO: set third plot to display usage vs reach\n",
        "axes[2].scatter(df['daily_usage'], df['avg_reach'], alpha=0.6, s=30)\n",
        "axes[2].set_xlabel('Daily Usage')\n",
        "axes[2].set_ylabel('Average Reach')\n",
        "axes[2].set_title('Usage vs Reach')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2eaa198",
      "metadata": {},
      "source": [
        "### TODO: Creating the feature matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6945c9ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: use to_numpy method to convert df to a numpy array\n",
        "X = ...\n",
        "\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"X type: {type(X)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e88edffa",
      "metadata": {},
      "source": [
        "### TODO: Finding the optimal k using silhouette scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d527ec2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Compute silhouette scores for k = 2 to 10\n",
        "k_range = ...\n",
        "silhouette_scores = []\n",
        "inertias = []\n",
        "\n",
        "for k in k_range:\n",
        "    # TODO: Initialize KMeans with k clusters, init='k-means++', random_state=42\n",
        "    kmeans = ...\n",
        "    \n",
        "    # TODO: Fit the model using KMeans' fit_predict method and get cluster labels\n",
        "    labels = ...\n",
        "    \n",
        "    # TODO: Calculate the silhouette score using sklearn silhouette score method (hint: see imports)\n",
        "    sil_score = ...\n",
        "    silhouette_scores.append(sil_score)\n",
        "    \n",
        "    # Also store within cluster distances for the elbow method comparison\n",
        "    inertias.append(kmeans.inertia_)\n",
        "    \n",
        "    print(f\"k={k}: Silhouette Score = {sil_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4c0eedb",
      "metadata": {},
      "source": [
        "### TODO: Visualizing silhouette scores vs elbow method\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03dc9341",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot both methods side by side\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Silhouette Score Plot\n",
        "axes[0].plot(list(k_range), silhouette_scores, 'bo-', linewidth=2, markersize=8)\n",
        "axes[0].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
        "axes[0].set_ylabel('Silhouette Score', fontsize=12)\n",
        "axes[0].set_title('Silhouette Score Method', fontsize=14)\n",
        "axes[0].set_xticks(list(k_range))\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# TODO: Mark the k with the highest silhouette score using the silhouette_scores list from before\n",
        "max_k = ...\n",
        "\n",
        "# TODO: Find the max silhouette score\n",
        "max_score = ...\n",
        "\n",
        "\n",
        "# Elbow Method Plot (Within-cluster distances)\n",
        "axes[1].plot(list(k_range), inertias, 'go-', linewidth=2, markersize=8)\n",
        "axes[1].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
        "axes[1].set_ylabel('Within-cluster distance', fontsize=12)\n",
        "axes[1].set_title('Elbow Method', fontsize=14)\n",
        "axes[1].set_xticks(list(k_range))\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4befae2",
      "metadata": {},
      "source": [
        "### Silhouette Plots for Different k Values\n",
        "\n",
        "Silhouette plots show the silhouette coefficient for each sample, grouped by cluster. This helps us understand:\n",
        "- **Cluster thickness**: How many samples are in each cluster\n",
        "- **Cluster quality**: How well samples fit their clusters (wider bars = better fit)\n",
        "- **Cluster consistency**: Whether all clusters have similar quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48aaee0f",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def plot_silhouette(X, k, ax):\n",
        "    \"\"\"Create a silhouette plot for k clusters.\"\"\"\n",
        "    # Fit KMeans\n",
        "    kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42, n_init=10)\n",
        "    labels = kmeans.fit_predict(X)\n",
        "    \n",
        "    # Calculate silhouette scores\n",
        "    silhouette_avg = silhouette_score(X, labels)\n",
        "    sample_silhouette_values = silhouette_samples(X, labels)\n",
        "    \n",
        "    y_lower = 10\n",
        "    colors = cm.nipy_spectral(np.linspace(0, 1, k))\n",
        "    \n",
        "    for i in range(k):\n",
        "        # Get silhouette scores for samples in cluster i\n",
        "        ith_cluster_silhouette_values = sample_silhouette_values[labels == i]\n",
        "        ith_cluster_silhouette_values.sort()\n",
        "        \n",
        "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "        \n",
        "        ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
        "                         0, ith_cluster_silhouette_values,\n",
        "                         facecolor=colors[i], edgecolor=colors[i], alpha=0.7)\n",
        "        \n",
        "        # Label the clusters\n",
        "        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "        y_lower = y_upper + 10\n",
        "    \n",
        "    ax.set_title(f\"k = {k}, Avg Score = {silhouette_avg:.3f}\")\n",
        "    ax.set_xlabel(\"Silhouette Score\")\n",
        "    ax.set_ylabel(\"Cluster\")\n",
        "    \n",
        "    # Draw line for average silhouette score\n",
        "    ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\", label=f\"Avg: {silhouette_avg:.3f}\")\n",
        "    ax.set_xlim([-0.1, 1])\n",
        "    \n",
        "    return silhouette_avg\n",
        "\n",
        "# Create silhouette plots for k = 2, 3, 4, 5, 6\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "k_values = [2, 3, 4, 5, 6, 7]\n",
        "for idx, k in enumerate(k_values):\n",
        "    plot_silhouette(X, k, axes[idx])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle(\"Silhouette Plots for Different k Values\", fontsize=14, y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9485a4b3",
      "metadata": {},
      "source": [
        "### TODO: Interpreting silhouette plots\n",
        "\n",
        "Look at the silhouette plots above and answer:\n",
        "\n",
        "1. Which value of k produces the most uniform cluster sizes (similar heights)?\n",
        "\n",
        "2. Which k value has the highest average silhouette score?\n",
        "\n",
        "3. Based on the silhouette analysis, what is the optimal k for this dataset?\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tempenv (3.13.2)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
